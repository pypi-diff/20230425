# Comparing `tmp/DDesignerAPI-0.0.1.5-py3-none-any.whl.zip` & `tmp/DDesignerAPI-0.0.1.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,20 +1,33 @@
-Zip file size: 29775 bytes, number of entries: 18
--rw-rw-r--  2.0 unx      726 b- defN 23-Apr-24 07:15 ddesigner_api/__init__.py
--rw-rw-r--  2.0 unx      873 b- defN 23-Apr-24 07:21 ddesigner_api/tensorflow/__init__.py
--rw-rw-r--  2.0 unx    11329 b- defN 23-Apr-24 10:04 ddesigner_api/tensorflow/dpi_blocks.py
--rw-rw-r--  2.0 unx     6208 b- defN 23-Apr-24 05:44 ddesigner_api/tensorflow/dpi_layers.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-24 07:24 ddesigner_api/tensorflow/examples/__init__.py
--rw-rw-r--  2.0 unx     2328 b- defN 23-Apr-24 10:24 ddesigner_api/tensorflow/examples/examples_keras.py
--rw-rw-r--  2.0 unx     2953 b- defN 23-Apr-24 10:25 ddesigner_api/tensorflow/examples/examples_tensorflow.py
--rw-rw-r--  2.0 unx      790 b- defN 23-Apr-24 07:16 ddesigner_api/tensorflow/xwn/__init__.py
--rw-rw-r--  2.0 unx    16322 b- defN 23-Apr-24 10:13 ddesigner_api/tensorflow/xwn/base_conv.py
--rw-rw-r--  2.0 unx    29774 b- defN 23-Apr-24 10:03 ddesigner_api/tensorflow/xwn/keras_layers.py
--rw-rw-r--  2.0 unx     4297 b- defN 23-Apr-24 05:44 ddesigner_api/tensorflow/xwn/keras_opt.py
--rw-rw-r--  2.0 unx     9240 b- defN 23-Apr-24 10:28 ddesigner_api/tensorflow/xwn/tf_nn.py
--rw-rw-r--  2.0 unx     3432 b- defN 23-Apr-24 10:31 ddesigner_api/tensorflow/xwn/tf_opt.py
--rwxrwxr-x  2.0 unx     9136 b- defN 23-Apr-24 10:32 DDesignerAPI-0.0.1.5.dist-info/LICENSE
--rw-rw-r--  2.0 unx     2793 b- defN 23-Apr-24 10:32 DDesignerAPI-0.0.1.5.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-24 10:32 DDesignerAPI-0.0.1.5.dist-info/WHEEL
--rw-rw-r--  2.0 unx       14 b- defN 23-Apr-24 10:32 DDesignerAPI-0.0.1.5.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     1689 b- defN 23-Apr-24 10:32 DDesignerAPI-0.0.1.5.dist-info/RECORD
-18 files, 101996 bytes uncompressed, 26937 bytes compressed:  73.6%
+Zip file size: 53993 bytes, number of entries: 31
+-rw-rw-r--  2.0 unx      726 b- defN 23-Apr-24 07:15 _ddesigner_api/__init__.py
+-rw-rw-r--  2.0 unx      873 b- defN 23-Apr-24 07:21 _ddesigner_api/tensorflow/__init__.py
+-rw-rw-r--  2.0 unx    11329 b- defN 23-Apr-24 10:04 _ddesigner_api/tensorflow/dpi_blocks.py
+-rw-rw-r--  2.0 unx     6208 b- defN 23-Apr-24 05:44 _ddesigner_api/tensorflow/dpi_layers.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Apr-24 07:24 _ddesigner_api/tensorflow/examples/__init__.py
+-rw-rw-r--  2.0 unx     3680 b- defN 23-Apr-24 14:42 _ddesigner_api/tensorflow/examples/examples_keras.py
+-rw-rw-r--  2.0 unx     2953 b- defN 23-Apr-24 10:25 _ddesigner_api/tensorflow/examples/examples_tensorflow.py
+-rw-rw-r--  2.0 unx      790 b- defN 23-Apr-24 07:16 _ddesigner_api/tensorflow/xwn/__init__.py
+-rw-rw-r--  2.0 unx    16346 b- defN 23-Apr-24 14:52 _ddesigner_api/tensorflow/xwn/base_conv.py
+-rw-rw-r--  2.0 unx    29804 b- defN 23-Apr-24 14:52 _ddesigner_api/tensorflow/xwn/keras_layers.py
+-rw-rw-r--  2.0 unx     4751 b- defN 23-Apr-24 15:31 _ddesigner_api/tensorflow/xwn/keras_opt.py
+-rw-rw-r--  2.0 unx     9240 b- defN 23-Apr-24 10:28 _ddesigner_api/tensorflow/xwn/tf_nn.py
+-rw-rw-r--  2.0 unx     3432 b- defN 23-Apr-24 10:31 _ddesigner_api/tensorflow/xwn/tf_opt.py
+-rw-rw-r--  2.0 unx      726 b- defN 23-Apr-25 00:24 ddesigner_api/__init__.py
+-rw-rw-r--  2.0 unx      873 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/__init__.py
+-rw-rw-r--  2.0 unx    11329 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/dpi_blocks.py
+-rw-rw-r--  2.0 unx     6208 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/dpi_layers.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/examples/__init__.py
+-rw-rw-r--  2.0 unx     2328 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/examples/examples_keras.py
+-rw-rw-r--  2.0 unx     2953 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/examples/examples_tensorflow.py
+-rw-rw-r--  2.0 unx      790 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/xwn/__init__.py
+-rw-rw-r--  2.0 unx    16322 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/xwn/base_conv.py
+-rw-rw-r--  2.0 unx    29451 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/xwn/keras_layers.py
+-rw-rw-r--  2.0 unx     4867 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/xwn/keras_opt.py
+-rw-rw-r--  2.0 unx     9240 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/xwn/tf_nn.py
+-rw-rw-r--  2.0 unx     3835 b- defN 23-Apr-25 00:24 ddesigner_api/tensorflow/xwn/tf_opt.py
+-rwxrwxr-x  2.0 unx     9136 b- defN 23-Apr-25 00:25 DDesignerAPI-0.0.1.6.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     2842 b- defN 23-Apr-25 00:25 DDesignerAPI-0.0.1.6.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Apr-25 00:25 DDesignerAPI-0.0.1.6.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       29 b- defN 23-Apr-25 00:25 DDesignerAPI-0.0.1.6.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     2970 b- defN 23-Apr-25 00:25 DDesignerAPI-0.0.1.6.dist-info/RECORD
+31 files, 194123 bytes uncompressed, 49081 bytes compressed:  74.7%
```

## zipnote {}

```diff
@@ -1,7 +1,46 @@
+Filename: _ddesigner_api/__init__.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/__init__.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/dpi_blocks.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/dpi_layers.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/examples/__init__.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/examples/examples_keras.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/examples/examples_tensorflow.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/xwn/__init__.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/xwn/base_conv.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/xwn/keras_layers.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/xwn/keras_opt.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/xwn/tf_nn.py
+Comment: 
+
+Filename: _ddesigner_api/tensorflow/xwn/tf_opt.py
+Comment: 
+
 Filename: ddesigner_api/__init__.py
 Comment: 
 
 Filename: ddesigner_api/tensorflow/__init__.py
 Comment: 
 
 Filename: ddesigner_api/tensorflow/dpi_blocks.py
@@ -33,23 +72,23 @@
 
 Filename: ddesigner_api/tensorflow/xwn/tf_nn.py
 Comment: 
 
 Filename: ddesigner_api/tensorflow/xwn/tf_opt.py
 Comment: 
 
-Filename: DDesignerAPI-0.0.1.5.dist-info/LICENSE
+Filename: DDesignerAPI-0.0.1.6.dist-info/LICENSE
 Comment: 
 
-Filename: DDesignerAPI-0.0.1.5.dist-info/METADATA
+Filename: DDesignerAPI-0.0.1.6.dist-info/METADATA
 Comment: 
 
-Filename: DDesignerAPI-0.0.1.5.dist-info/WHEEL
+Filename: DDesignerAPI-0.0.1.6.dist-info/WHEEL
 Comment: 
 
-Filename: DDesignerAPI-0.0.1.5.dist-info/top_level.txt
+Filename: DDesignerAPI-0.0.1.6.dist-info/top_level.txt
 Comment: 
 
-Filename: DDesignerAPI-0.0.1.5.dist-info/RECORD
+Filename: DDesignerAPI-0.0.1.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## ddesigner_api/tensorflow/xwn/keras_layers.py

```diff
@@ -13,19 +13,25 @@
 # limitations under the License.
 # ==============================================================================
 """Keras 2D convolution layer."""
 
 
 import tensorflow.compat.v2 as tf
 
-from tensorflow.keras import activations
-from tensorflow.keras import constraints
-from tensorflow.keras import initializers
-from tensorflow.keras import regularizers
-from tensorflow.keras import backend
+from tensorflow.python.eager import context
+from tensorflow.python.framework import tensor_shape
+from tensorflow.python.keras import activations
+from tensorflow.python.keras import backend
+from tensorflow.python.keras import constraints
+from tensorflow.python.keras import initializers
+from tensorflow.python.keras import regularizers
+from tensorflow.python.keras.engine.input_spec import InputSpec
+from tensorflow.python.keras.utils import conv_utils
+from tensorflow.python.ops import array_ops
+from tensorflow.python.ops import nn
 # from tensorflow.keras.dtensor import utils
 
 from .base_conv import Conv
 from .keras_opt import Optimization
 
 
 
@@ -507,169 +513,166 @@
 
         # Add optimization kernel
         self.opt = Optimization(
             use_transform=use_transform, 
             bit=bit, 
             max_scale=max_scale,
             use_pruning=use_pruning, 
-            prun_weight=prun_weight
+            prun_weight=prun_weight,
+            transpose=True,
         )
     
-        def build(self, input_shape):
-          input_shape = tensor_shape.TensorShape(input_shape)
-          if len(input_shape) != 4:
-            raise ValueError('Inputs should have rank 4. Received input '
-                             'shape: ' + str(input_shape))
-          channel_axis = self._get_channel_axis()
-          if input_shape.dims[channel_axis].value is None:
-            raise ValueError('The channel dimension of the inputs '
-                             'should be defined. Found `None`.')
-          input_dim = int(input_shape[channel_axis])
-          self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})
-          kernel_shape = self.kernel_size + (self.filters, input_dim)
-        
-          self.kernel = self.add_weight(
-              name='kernel',
-              shape=kernel_shape,
-              initializer=self.kernel_initializer,
-              regularizer=self.kernel_regularizer,
-              constraint=self.kernel_constraint,
-              trainable=True,
-              dtype=self.dtype)
-          if self.use_bias:
-            self.bias = self.add_weight(
-                name='bias',
-                shape=(self.filters,),
-                initializer=self.bias_initializer,
-                regularizer=self.bias_regularizer,
-                constraint=self.bias_constraint,
-                trainable=True,
-                dtype=self.dtype)
-          else:
-            self.bias = None
-          self.built = True
-        
-          self.opt.set_shape(self.kernel_size + (input_dim, self.filters))
-
-        def call(self, inputs):
-          inputs_shape = array_ops.shape(inputs)
-          batch_size = inputs_shape[0]
-          if self.data_format == 'channels_first':
-            h_axis, w_axis = 2, 3
-          else:
-            h_axis, w_axis = 1, 2
-        
-          # Use the constant height and weight when possible.
-          # TODO(scottzhu): Extract this into a utility function that can be applied
-          # to all convolutional layers, which currently lost the static shape
-          # information due to tf.shape().
-          height, width = None, None
-          if inputs.shape.rank is not None:
-            dims = inputs.shape.as_list()
-            height = dims[h_axis]
-            width = dims[w_axis]
-          height = height if height is not None else inputs_shape[h_axis]
-          width = width if width is not None else inputs_shape[w_axis]
-        
-          kernel_h, kernel_w = self.kernel_size
-          stride_h, stride_w = self.strides
-        
-          if self.output_padding is None:
-            out_pad_h = out_pad_w = None
-          else:
-            out_pad_h, out_pad_w = self.output_padding
-        
-          # Infer the dynamic output shape:
-          out_height = conv_utils.deconv_output_length(height,
-                                                       kernel_h,
-                                                       padding=self.padding,
-                                                       output_padding=out_pad_h,
-                                                       stride=stride_h,
-                                                       dilation=self.dilation_rate[0])
-          out_width = conv_utils.deconv_output_length(width,
-                                                      kernel_w,
-                                                      padding=self.padding,
-                                                      output_padding=out_pad_w,
-                                                      stride=stride_w,
-                                                      dilation=self.dilation_rate[1])
-          if self.data_format == 'channels_first':
-            output_shape = (batch_size, self.filters, out_height, out_width)
-          else:
-            output_shape = (batch_size, out_height, out_width, self.filters)
-        
-          output_shape_tensor = array_ops.stack(output_shape)
-
-          kernel = tf.transpose(
-            self.opt.optimize(
-              tf.transpose(self.kernel), (0,1,3,2)
-            ), (0,1,3,2)
-          )
-
-          outputs = backend.conv2d_transpose(
-              inputs,
-              # self.kernel,
-              kernel,
-              output_shape_tensor,
-              strides=self.strides,
-              padding=self.padding,
-              data_format=self.data_format,
-              dilation_rate=self.dilation_rate)
-        
-          if not context.executing_eagerly():
-            # Infer the static output shape:
-            out_shape = self.compute_output_shape(inputs.shape)
-            outputs.set_shape(out_shape)
-        
-          if self.use_bias:
-            outputs = nn.bias_add(
-                outputs,
-                self.bias,
-                data_format=conv_utils.convert_data_format(self.data_format, ndim=4))
-        
-          if self.activation is not None:
-            return self.activation(outputs)
-          return outputs
-        
-        def compute_output_shape(self, input_shape):
-          input_shape = tensor_shape.TensorShape(input_shape).as_list()
-          output_shape = list(input_shape)
-          if self.data_format == 'channels_first':
-            c_axis, h_axis, w_axis = 1, 2, 3
-          else:
-            c_axis, h_axis, w_axis = 3, 1, 2
-        
-          kernel_h, kernel_w = self.kernel_size
-          stride_h, stride_w = self.strides
-        
-          if self.output_padding is None:
-            out_pad_h = out_pad_w = None
-          else:
-            out_pad_h, out_pad_w = self.output_padding
-        
-          output_shape[c_axis] = self.filters
-          output_shape[h_axis] = conv_utils.deconv_output_length(
-              output_shape[h_axis],
-              kernel_h,
-              padding=self.padding,
-              output_padding=out_pad_h,
-              stride=stride_h,
-              dilation=self.dilation_rate[0])
-          output_shape[w_axis] = conv_utils.deconv_output_length(
-              output_shape[w_axis],
-              kernel_w,
-              padding=self.padding,
-              output_padding=out_pad_w,
-              stride=stride_w,
-              dilation=self.dilation_rate[1])
-          return tensor_shape.TensorShape(output_shape)
-        
-        def get_config(self):
-          config = super(Conv2DTranspose, self).get_config()
-          config['output_padding'] = self.output_padding
-          return config
+    def build(self, input_shape):
+      input_shape = tensor_shape.TensorShape(input_shape)
+      if len(input_shape) != 4:
+        raise ValueError('Inputs should have rank 4. Received input '
+                         'shape: ' + str(input_shape))
+      channel_axis = self._get_channel_axis()
+      if input_shape.dims[channel_axis].value is None:
+        raise ValueError('The channel dimension of the inputs '
+                         'should be defined. Found `None`.')
+      input_dim = int(input_shape[channel_axis])
+      self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})
+      kernel_shape = self.kernel_size + (self.filters, input_dim)
+    
+      self.kernel = self.add_weight(
+          name='kernel',
+          shape=kernel_shape,
+          initializer=self.kernel_initializer,
+          regularizer=self.kernel_regularizer,
+          constraint=self.kernel_constraint,
+          trainable=True,
+          dtype=self.dtype)
+      if self.use_bias:
+        self.bias = self.add_weight(
+            name='bias',
+            shape=(self.filters,),
+            initializer=self.bias_initializer,
+            regularizer=self.bias_regularizer,
+            constraint=self.bias_constraint,
+            trainable=True,
+            dtype=self.dtype)
+      else:
+        self.bias = None
+      self.built = True
+    
+      self.opt.set_shape(self.kernel_size + (input_dim, self.filters))
+
+    def call(self, inputs):
+      inputs_shape = array_ops.shape(inputs)
+      batch_size = inputs_shape[0]
+      if self.data_format == 'channels_first':
+        h_axis, w_axis = 2, 3
+      else:
+        h_axis, w_axis = 1, 2
+    
+      # Use the constant height and weight when possible.
+      # TODO(scottzhu): Extract this into a utility function that can be applied
+      # to all convolutional layers, which currently lost the static shape
+      # information due to tf.shape().
+      height, width = None, None
+      if inputs.shape.rank is not None:
+        dims = inputs.shape.as_list()
+        height = dims[h_axis]
+        width = dims[w_axis]
+      height = height if height is not None else inputs_shape[h_axis]
+      width = width if width is not None else inputs_shape[w_axis]
+    
+      kernel_h, kernel_w = self.kernel_size
+      stride_h, stride_w = self.strides
+    
+      if self.output_padding is None:
+        out_pad_h = out_pad_w = None
+      else:
+        out_pad_h, out_pad_w = self.output_padding
+    
+      # Infer the dynamic output shape:
+      out_height = conv_utils.deconv_output_length(height,
+                                                   kernel_h,
+                                                   padding=self.padding,
+                                                   output_padding=out_pad_h,
+                                                   stride=stride_h,
+                                                   dilation=self.dilation_rate[0])
+      out_width = conv_utils.deconv_output_length(width,
+                                                  kernel_w,
+                                                  padding=self.padding,
+                                                  output_padding=out_pad_w,
+                                                  stride=stride_w,
+                                                  dilation=self.dilation_rate[1])
+      if self.data_format == 'channels_first':
+        output_shape = (batch_size, self.filters, out_height, out_width)
+      else:
+        output_shape = (batch_size, out_height, out_width, self.filters)
+    
+      output_shape_tensor = array_ops.stack(output_shape)
+
+      kernel = self.opt.optimize(self.kernel)
+
+      outputs = backend.conv2d_transpose(
+          inputs,
+          # self.kernel,
+          kernel,
+          output_shape_tensor,
+          strides=self.strides,
+          padding=self.padding,
+          data_format=self.data_format,
+          dilation_rate=self.dilation_rate)
+    
+      if not context.executing_eagerly():
+        # Infer the static output shape:
+        out_shape = self.compute_output_shape(inputs.shape)
+        outputs.set_shape(out_shape)
+    
+      if self.use_bias:
+        outputs = nn.bias_add(
+            outputs,
+            self.bias,
+            data_format=conv_utils.convert_data_format(self.data_format, ndim=4))
+    
+      if self.activation is not None:
+        return self.activation(outputs)
+      return outputs
+    
+    def compute_output_shape(self, input_shape):
+      input_shape = tensor_shape.TensorShape(input_shape).as_list()
+      output_shape = list(input_shape)
+      if self.data_format == 'channels_first':
+        c_axis, h_axis, w_axis = 1, 2, 3
+      else:
+        c_axis, h_axis, w_axis = 3, 1, 2
+    
+      kernel_h, kernel_w = self.kernel_size
+      stride_h, stride_w = self.strides
+    
+      if self.output_padding is None:
+        out_pad_h = out_pad_w = None
+      else:
+        out_pad_h, out_pad_w = self.output_padding
+    
+      output_shape[c_axis] = self.filters
+      output_shape[h_axis] = conv_utils.deconv_output_length(
+          output_shape[h_axis],
+          kernel_h,
+          padding=self.padding,
+          output_padding=out_pad_h,
+          stride=stride_h,
+          dilation=self.dilation_rate[0])
+      output_shape[w_axis] = conv_utils.deconv_output_length(
+          output_shape[w_axis],
+          kernel_w,
+          padding=self.padding,
+          output_padding=out_pad_w,
+          stride=stride_w,
+          dilation=self.dilation_rate[1])
+      return tensor_shape.TensorShape(output_shape)
+    
+    def get_config(self):
+      config = super(Conv2DTranspose, self).get_config()
+      config['output_padding'] = self.output_padding
+      return config
 
 
 # Alias
 
 Convolution2D = Conv2D
 Convolution1D = Conv1D
 Convolution2DTranspose = Conv2DTranspose
```

## ddesigner_api/tensorflow/xwn/keras_opt.py

```diff
@@ -13,34 +13,37 @@
 # limitations under the License.
 # ==============================================================================
 
 import os
 os.environ['TF_DETERMINISTIC_OPS'] = '0'
 
 import tensorflow as tf
+import tensorflow.compat.v1 as tf_v1
 
 
 
 class Optimization:
     def __init__(
         self, 
         use_transform=False, 
         bit=1, 
         max_scale=4.0,
         use_pruning=False, 
         prun_weight=0.50,
         method='L1',
+        transpose=False,
         ):
 
         self.bit = bit
         self.max_scale = max_scale
         self.use_transform = use_transform
         self.use_pruning = use_pruning
         self.prun_weight = prun_weight
         self.method = method
+        self.transpose = transpose
 
         self.dtype = 'float32'
         self.bit_scale = tf.constant(bit - 1, dtype=self.dtype)
         self.num_scale = tf.cast(tf.pow(2, self.bit_scale), tf.int64)
         self.map_scale = self._get_coeff()
 
     def _get_coeff(self):
@@ -116,23 +119,37 @@
             tf.less(x_mag, m_mag * self.prun_weight), 
             tf.zeros_like(x_mag, dtype=self.dtype), 
             tf.ones_like(x_mag, dtype=self.dtype)
         ) # (i,o)
     
         return mask
 
-
     def optimize(self, x):
         '''
         x is AutoCastDistribuedVariable
         '''
-        x_tr = self._transform(x)
-        x_mask = self._pruning(x)
-        x = tf.compat.v1.assign(x, x_tr * x_mask)
+        _x = tf.transpose(x, self.transpose_axis)
+        x_tr = self._transform(_x)
+        x_mask = self._pruning(_x)
+        x_opt = x_tr * x_mask
+        _x = tf.transpose(x_opt, self.transpose_axis)
+        x = tf_v1.assign(x, _x)
+
         return x
 
     def set_shape(self, shape):
         self.shape = shape
         self.bypass_transform = (self.bit < 1) or not self.use_transform
         self.kernel_axis = list(range(len(shape) - 2))
 
+        if len(self.shape) == 4:
+            if self.transpose:
+                self.transpose_axis = (0,1,3,2)
+            else:
+                self.transpose_axis = (0,1,2,3)
+        elif len(self.shape) == 3:
+            if self.transpose:
+                self.transpose_axis = (0,2,1)
+            else:
+                self.transpose_axis = (0,1,2)
+
```

## ddesigner_api/tensorflow/xwn/tf_opt.py

```diff
@@ -113,22 +113,36 @@
     x, 
     use_transform=False, 
     bit=1, 
     max_scale=4.0,
     use_pruning=False, 
     prun_weight=0.50, 
     method='L1',
+    transpose=False,
     ):
+    if len(x.get_shape().dims) == 4:
+        if transpose: 
+            transpose_axis = (0,1,3,2)
+        else:
+            transpose_axis = (0,1,2,3)
+    elif len(x.get_shape().dims) == 3:
+        if transpose:
+            transpose_axis = (0,2,1)
+        else:
+            transpose_axis = (0,1,2)
+
+    x = tf.transpose(x, transpose_axis)
     x_tr = transform(
         x, 
         bit=bit, 
         max_scale=max_scale, 
         valid=use_transform,
         method=method,
     )
 
     x_mask = pruning(x, valid=use_pruning, weight=prun_weight)
     x = x_tr * x_mask
+    x = tf.transpose(x, transpose_axis)
 
     return x
```

## Comparing `DDesignerAPI-0.0.1.5.dist-info/LICENSE` & `DDesignerAPI-0.0.1.6.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `DDesignerAPI-0.0.1.5.dist-info/METADATA` & `DDesignerAPI-0.0.1.6.dist-info/METADATA`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: DDesignerAPI
-Version: 0.0.1.5
+Version: 0.0.1.6
 Summary: Deep-learning Designer: Deep-Learning Training Optimization & Layers API(like Keras)
 Home-page: https://github.com/DPI/TrainingAPI
 Author: dean
 Author-email: dean@deeper-i.com
 License: Apache-2.0
 Keywords: dpi,xwn,tensorflow,keras
 Platform: UNKNOWN
@@ -18,15 +18,15 @@
 # 1. About
 ## 1.1. DDesignerAPI?
 It is a API for deep-learning learning and inference, and an API for application development using multi-platform
 
 ## 1.2. Functions
 ### 1.2.1. Layers and Blocks
 * The ability to define special layers that are not defined in Keras and others
-* A function that defines a combination of layers as a block and easily composes a block
+* A function that defines a combination of layers as a block and easily composes a block (ex. CONV + BN + ACT + DROPOUT + SE = ConvBlock)
 
 ### 1.2.2. Optimization for Accelerator Usage (XWN)
 * Optimized function to use accelerator
 
 
 # 2. Support
 ## 2.1. Platforms
```

